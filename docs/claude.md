# Instructions for Claude (AI Assistant) Working on neural-analysis

This document provides critical instructions for Claude Sonnet (or any AI assistant) when making changes to this repository.

## üö® CRITICAL RULES - NEVER VIOLATE

### Rule 0: **ALWAYS USE PLOTGRID FOR PLOTTING**
**All plotting in this package MUST use the PlotGrid system.**

```python
# ‚úÖ CORRECT: Use PlotGrid
from neural_analysis.plotting import PlotGrid, PlotSpec, GridLayoutConfig

specs = [
    PlotSpec(data=data1, plot_type='scatter', label='A', color='blue'),
    PlotSpec(data=data2, plot_type='scatter', label='B', color='red'),
]
grid = PlotGrid(plot_specs=specs, layout=GridLayoutConfig(rows=1, cols=2))
fig = grid.plot()

# ‚ùå WRONG: Direct matplotlib/plotly calls
import matplotlib.pyplot as plt
plt.scatter(x, y)  # DON'T DO THIS
```

**Why PlotGrid?**
- Metadata-driven: Configuration as data
- Consistent styling across all visualizations
- Multi-panel layouts with `subplot_position`
- Backend agnostic (matplotlib ‚Üî plotly)
- Legend deduplication
- Type-safe with Literal type hints

**Helper Functions**: Convenience functions like `plot_bar()`, `plot_violin()` internally use PlotGrid.

### Rule 1: Always Run Local CI Before Pushing
**NEVER push code without running and passing local CI checks first.**

```bash
# MANDATORY before every push
./scripts/run_ci_locally.sh
```

If you cannot run `act` (Docker/local CI), then run all checks manually:
```bash
uv run -- ruff check src tests
uv run -- mypy src tests
uv run -- pytest -v
```

**Why?** This ensures code quality, saves GitHub Actions minutes, and maintains repository standards.

### Rule 2: Never Push Directly to Main
- Main branch is protected
- All changes must go through pull requests
- CI must pass before merging
- Use feature branches: `feat/description`, `fix/description`, `chore/description`

### Rule 3: Follow Project Structure
```
neural-analysis/
‚îú‚îÄ‚îÄ src/neural_analysis/     # Main package code
‚îú‚îÄ‚îÄ tests/                    # All tests mirror src/ structure
‚îú‚îÄ‚îÄ docs/                     # Documentation
‚îú‚îÄ‚îÄ scripts/                  # Automation scripts
‚îú‚îÄ‚îÄ .github/workflows/        # CI/CD pipelines
‚îú‚îÄ‚îÄ pyproject.toml           # Project config and dependencies
‚îî‚îÄ‚îÄ uv.lock                  # Locked dependency versions
```

### Rule 4: Use uv for All Package Management
```bash
# NEVER use pip install
# ALWAYS use uv

# Add dependency
uv add package-name

# Add dev dependency  
uv add --dev package-name

# Install dependencies
uv sync --locked --all-extras

# Run commands
uv run -- command
```

### Rule 5: MAXIMIZE CODE REUSE - Check Registry First

**Before writing new code, ALWAYS check the function registry!**

```bash
# Generate/update function registry
python3 scripts/generate_function_registry.py

# Check registry for existing functions
cat docs/function_registry.md  # Human-readable
cat docs/function_registry.json  # Machine-readable
```

**Code Reuse Rules:**
1. **Search before implementing**: Check `docs/function_registry.md` for existing functions
2. **Use renderer functions**: For plot rendering, use functions from `renderers.py`
3. **No duplicate logic**: If similar code exists, refactor into shared function
4. **Layer appropriately**:
   - `renderers.py`: Low-level rendering (matplotlib/plotly primitives)
   - `plots_*.py`: Standalone plotting functions (legacy, direct API calls)
   - `grid_config.py`: PlotGrid system (uses renderers)
   - `statistical_plots.py`: High-level convenience (uses PlotGrid)

**Function Registry Auto-Generation:**
The registry is auto-generated by scanning all Python files in `src/neural_analysis/plotting/`.
Run `scripts/generate_function_registry.py` after adding new functions.

**Why This Matters:**
- Reduces code duplication (DRY principle)
- Makes codebase easier to maintain
- Helps AI agents find existing functionality
- Ensures consistent behavior across similar operations

## Project Overview

### Purpose
Automated pipeline for building and testing neural analysis methods with:
- Reproducible environments (uv + uv.lock)
- Automated quality gates (ruff, mypy, pytest)
- Local CI testing (act)
- GitHub Actions CI/CD

### Tech Stack
- **Python**: 3.14+
- **Package Manager**: uv (Astral)
- **Testing**: pytest + pytest-xdist + pytest-cov
- **Type Checking**: mypy
- **Linting**: ruff
- **Pre-commit**: Local hooks (optional)
- **CI**: GitHub Actions + act (local)

### Key Files
- `pyproject.toml` - Project metadata, dependencies, tool configuration
- `uv.lock` - Locked dependency versions (DO NOT manually edit)
- `.github/workflows/ci.yml` - CI pipeline configuration
- `scripts/setup_env.sh` - Environment bootstrap script
- `scripts/run_ci_locally.sh` - Local CI runner

### Planned Structure (Future Expansion)

**IMPORTANT**: When creating new modules, follow this planned directory structure to ensure consistency as the project grows.

```
neural_analysis_repo/
‚îÇ
‚îú‚îÄ‚îÄ data/                   # Raw and processed data
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Original unmodified datasets
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Preprocessed datasets ready for analysis
‚îÇ   ‚îî‚îÄ‚îÄ external/           # External data or reference datasets
‚îÇ
‚îú‚îÄ‚îÄ notebooks/              # Jupyter notebooks for exploration and demos
‚îÇ   ‚îî‚îÄ‚îÄ examples.ipynb
‚îÇ
‚îú‚îÄ‚îÄ src/                    # All source code for analysis
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/              # General utility functions (file IO, logging, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ io_utils.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ math_utils.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/      # Data cleaning, normalization, filtering
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ signal_processing.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ analysis/           # Core analysis methods
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py    # Neural embedding / dimensionality reduction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ connectivity.py # Functional or structural connectivity analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spike_analysis.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ plotting/           # Plotting functions / figure templates
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ raster_plot.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ summary_figures.py
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models/             # Optional: ML/Deep Learning models
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ autoencoder.py
‚îÇ       ‚îî‚îÄ‚îÄ classifier.py
‚îÇ
‚îú‚îÄ‚îÄ tests/                  # Unit tests for all modules
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py
‚îÇ   ‚îú‚îÄ‚îÄ test_embedding.py
‚îÇ   ‚îî‚îÄ‚îÄ test_plotting.py
‚îÇ
‚îú‚îÄ‚îÄ docs/                   # Documentation, methodology notes
‚îÇ
‚îú‚îÄ‚îÄ results/                # Generated outputs (plots, embeddings, tables)
‚îÇ   ‚îú‚îÄ‚îÄ figures/
‚îÇ   ‚îî‚îÄ‚îÄ tables/
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ setup.py / pyproject.toml # Package info
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ .gitignore
```

**Current Implementation Note**: The `visualization` module (containing `plots_1d`, `plots_2d`, etc.) is currently being migrated from the legacy `Visualizer.py`. Once migration is complete, consider whether to keep the name `visualization` or rename to `plotting` to match the planned structure above.

## Development Workflow for Claude

### When Making Changes

1. **Understand the request** - Read user requirements carefully
2. **Check existing code** - Use grep/search tools to understand context
3. **Make changes** - Edit files following project conventions
4. **Run quality checks** - ALWAYS run before pushing:
   ```bash
   ./scripts/run_ci_locally.sh
   ```
5. **Commit changes** - Use conventional commit messages
6. **Push to feature branch** - Never push directly to main
7. **Create/update PR** - Ensure CI passes before requesting merge

### Conventional Commit Messages

```bash
# Feature
git commit -m "feat: add new neural analysis method"

# Bug fix
git commit -m "fix: correct calculation in normalize function"

# Documentation
git commit -m "docs: update README with usage examples"

# Tests
git commit -m "test: add tests for edge cases in mean function"

# Refactor
git commit -m "refactor: simplify data preprocessing pipeline"

# Chore (maintenance)
git commit -m "chore: update dependencies in pyproject.toml"

# CI/CD changes
git commit -m "ci: update GitHub Actions workflow"
```

## Logging is essential

To make analyses reproducible and debuggable, avoid `print()` in library code. Use the project logger instead:

- Configure once in your script or notebook:
    ```python
    from neural_analysis.utils import configure_logging
    configure_logging(level="INFO")  # optional file_path="logs/run.log"
    ```
- Get a namespaced logger in modules:
    ```python
    from neural_analysis.utils import get_logger
    log = get_logger(__name__)
    log.info("Starting analysis")
    ```
- Log structured metrics:
    ```python
    from neural_analysis.utils import log_kv
    log_kv("metrics", {"acc": 0.93, "loss": 0.12})
    ```
- Create readable sections:
    ```python
    from neural_analysis.utils import log_section
    log_section("Phase 1: Loading data")
    ```

See `docs/logging.md` for full guidelines, environment variables, and decorators.

### Code Style Guidelines

#### Python Code
```python
"""Module docstring explaining purpose."""
from __future__ import annotations

from typing import Sequence


def function_name(param: type) -> return_type:
    """Function docstring.
    
    Args:
        param: Description of parameter
        
    Returns:
        Description of return value
        
    Raises:
        ValueError: When validation fails
    """
    # Implementation
    pass


class ClassName:
    """Class docstring."""
    
    def __init__(self, value: int) -> None:
        """Initialize the class."""
        self.value = value
```

#### Type Hints
- ‚úÖ Always use type hints for function parameters and returns
- ‚úÖ Use modern type syntax: `list[str]` not `List[str]`
- ‚úÖ Use `from __future__ import annotations` for forward references
- ‚úÖ Use `Sequence`, `Mapping` for generic containers when appropriate

#### Docstrings
- ‚úÖ Use Google-style docstrings
- ‚úÖ Document all public functions, classes, and modules
- ‚úÖ Include Args, Returns, Raises sections as needed
- ‚úÖ Keep docstrings concise but informative

#### Testing
- ‚úÖ Write tests for all new functions
- ‚úÖ Test normal cases, edge cases, and error cases
- ‚úÖ Use descriptive test names: `test_<what>_<condition>_<expected>`
- ‚úÖ Place tests in `tests/` mirroring `src/` structure

### Commands Reference

#### Environment Setup
```bash
# Initial setup
./scripts/setup_env.sh

# With options
INSTALL_DEV=1 RUN_LOCAL_CI=1 ./scripts/setup_env.sh
```

#### Running Checks
```bash
# Local CI (MANDATORY before push)
./scripts/run_ci_locally.sh

# Individual checks
uv run -- ruff check src tests
uv run -- ruff check src tests --fix  # Auto-fix
uv run -- mypy src tests
uv run -- pytest
uv run -- pytest -v  # Verbose
uv run -- pytest -n auto  # Parallel
uv run -- pytest --cov  # With coverage
```

#### Package Management
```bash
# Sync dependencies
uv sync --locked --all-extras

# Add dependency
uv add package-name

# Add dev dependency
uv add --dev package-name

# Update lock file
uv lock

# Remove package
uv remove package-name
```

#### Git Operations
```bash
# Create feature branch
git checkout -b feat/your-feature

# Stage changes
git add .

# Commit with message
git commit -m "feat: description"

# Push to feature branch
git push origin feat/your-feature

# Create PR (if gh CLI available)
gh pr create --title "feat: description" --body "Details" --base main
```

## Common Tasks for Claude

### Adding a New Feature
1. Create feature branch: `git checkout -b feat/feature-name`
2. Implement the feature in `src/neural_analysis/`
3. Add tests in `tests/`
4. Update documentation if needed
5. Run local CI: `./scripts/run_ci_locally.sh`
6. Commit: `git commit -m "feat: add feature"`
7. Push: `git push origin feat/feature-name`
8. Create PR

### Fixing a Bug
1. Create fix branch: `git checkout -b fix/bug-description`
2. Fix the bug in source code
3. Add test case that would catch the bug
4. Run local CI: `./scripts/run_ci_locally.sh`
5. Commit: `git commit -m "fix: resolve bug"`
6. Push and create PR

### Adding Dependencies
1. Add to pyproject.toml: `uv add package-name`
2. Or add to dev dependencies: `uv add --dev package-name`
3. Verify lock file updated: check `uv.lock`
4. Test that it works: `uv sync --locked --all-extras`
5. Commit: `git commit -m "chore: add package-name dependency"`

### Updating Documentation
1. Edit files in `docs/` or `README.md` or `CONTRIBUTING.md`
2. Ensure markdown is properly formatted
3. Run local CI to catch any issues: `./scripts/run_ci_locally.sh`
4. Commit: `git commit -m "docs: update documentation"`

## CI/CD Pipeline

### GitHub Actions Workflow
Location: `.github/workflows/ci.yml`

Steps executed on every push/PR:
1. Checkout code
2. Set up Python 3.14
3. Install uv
4. Verify uv.lock is up-to-date
5. Sync dependencies (locked)
6. Run ruff linting
7. Run mypy type checking
8. Run pytest tests

All steps must pass before PR can be merged.

### Local CI with act
```bash
# Run full CI locally
./scripts/run_ci_locally.sh

# Or use act directly
act -W .github/workflows/ci.yml

# With verbose output
act -W .github/workflows/ci.yml -v
```

**First run requires Docker images (~1-2 GB download)**

## Troubleshooting for Claude

### CI Fails with "uv: command not found"
```bash
# Reinstall uv
curl -LsSf https://astral.sh/uv/install.sh | sh
export PATH="$HOME/.local/bin:$PATH"
```

### Tests Pass Locally but Fail in CI
```bash
# Use locked dependencies
uv sync --locked --all-extras

# Check Python version
python --version  # Should be 3.14+
```

### Cannot Push to Main
- This is correct behavior! Main is protected.
- Create a feature branch instead
- Push to feature branch and create PR

### Local CI Script Fails
```bash
# Check Docker is running
docker ps

# Install Docker if missing
sudo apt install docker.io -y
sudo systemctl start docker

# Install act if missing
curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash
```

## Documentation Map

| File | Purpose |
|------|---------|
| `README.md` | Project overview and quick start |
| `CONTRIBUTING.md` | Contribution guidelines |
| `docs/python_testing_setup.md` | Detailed testing documentation |
| `docs/local_ci_testing.md` | Local CI with act guide |
| `docs/folder_structure.md` | Repository structure |
| `docs/project_goal.md` | Project mission and goals |
| `docs/claude.md` | This file - Instructions for AI assistants |

## Quality Standards

### All Code Must Have
- ‚úÖ Type hints on all function signatures
- ‚úÖ Docstrings on all public functions/classes/modules
- ‚úÖ Unit tests with >80% coverage
- ‚úÖ Pass ruff linting
- ‚úÖ Pass mypy type checking
- ‚úÖ Pass pytest tests

### All PRs Must Have
- ‚úÖ Descriptive title and description
- ‚úÖ All CI checks passing (green checkmarks)
- ‚úÖ No merge conflicts with main
- ‚úÖ Conventional commit messages

### Never
- ‚ùå Push directly to main
- ‚ùå Skip CI checks
- ‚ùå Use `pip install` (use `uv` instead)
- ‚ùå Commit without running local CI
- ‚ùå Use `--no-verify` to skip pre-commit hooks
- ‚ùå Force push to shared branches
- ‚ùå Manually edit `uv.lock`

## Success Checklist for Claude

Before saying "Done" to the user, verify:

- [ ] All changes committed with descriptive messages
- [ ] Local CI passed (`./scripts/run_ci_locally.sh`)
- [ ] Changes pushed to feature branch (not main)
- [ ] PR created (if requested)
- [ ] No errors in terminal output
- [ ] Documentation updated if needed
- [ ] Tests added for new features
- [ ] Code follows style guidelines

## Getting Help

If you (Claude) encounter issues:
1. Check error messages carefully
2. Review relevant documentation in `docs/`
3. Check if similar issues exist in git history
4. Consult `CONTRIBUTING.md` for workflow guidance
5. Ask the user for clarification if needed

## Summary

**Most Important Rules:**
1. üö® **ALWAYS run `./scripts/run_ci_locally.sh` before pushing**
2. üö® **NEVER push directly to main** - use feature branches
3. üö® **ALWAYS use `uv`** for package management, not pip
4. üö® **ALWAYS write tests** for new code
5. üö® **ALWAYS use type hints** and docstrings

Follow these rules and the project will maintain high quality standards! üöÄ

## Standard Procedures for Module Development

### Complete Module Implementation Checklist

When implementing a new module (e.g., plots_1d.py, plots_2d.py), follow these steps **IN ORDER**:

#### 1. Code Implementation
```bash
# Create module with:
# - Full type hints (numpy.typing.NDArray, Optional[], Union[], Literal[])
# - Comprehensive docstrings (NumPy style)
# - Usage examples in docstrings
# - Both matplotlib and plotly backend support (where applicable)
```

#### 2. Linting & Type Checking
```bash
# Run ruff linter and auto-fix issues
uv run ruff check src/neural_analysis/[module_path] --fix

# Run type checking
uv run mypy src/neural_analysis/[module_path] --strict
```

**Required Standards:**
- No ruff errors (E, W, F series)
- No type errors (accept plotly import-untyped warnings)
- Clean, idiomatic code

#### 3. Test Creation & Execution
```bash
# Run tests WITHOUT coverage first (faster)
uv run pytest tests/test_[module].py -v

# Run tests WITH coverage after all pass
uv run pytest tests/test_[module].py --cov=[module_name] --cov-report=term-missing
```

**Test Standards:**
- Aim for 100% code coverage
- Test all functions with multiple scenarios
- Include edge cases (empty data, NaN, infinity, single point)
- Test both backends (matplotlib and plotly)
- Use pytest fixtures for common data

#### 4. Example Notebook Creation
```bash
# Create Jupyter notebook: examples/[module]_examples.ipynb
# Must include:
# - Import cells with all dependencies
# - Example for each major function
# - Different parameter configurations
# - Output visualizations (plots displayed)
# - Clear markdown explanations
```

#### 5. Update pyproject.toml
```bash
# IF new dependencies were added during development:
# 1. Update dependencies list in pyproject.toml
# 2. Sync environment
uv sync

# 3. Reinstall in editable mode with extras
uv pip install -e ".[dev,viz]"
```

**When to Update:**
- New core dependencies (add to `dependencies`)
- New visualization dependencies (add to `optional-dependencies.viz`)
- New dev/testing tools (add to `optional-dependencies.dev`)

### Visualizer Migration Specific Procedures

When migrating functions from `todo/Visualizer.py`:

1. **Plan**: Identify 3-5 related functions to migrate together
2. **Implement**: Follow standard module checklist above
3. **Test**: Create comprehensive test suite (aim for 28+ tests per module)
4. **Document**: Create examples notebook showing all migrated functions
5. **Update Progress**: Update `docs/visualizer_migration_progress.md`

###Known Issues & Workarounds

#### NumPy 2.3.4 + Python 3.14 Incompatibility
**Issue**: NumPy 2.3+ causes matplotlib errors with Python 3.14  
**Solution**: Pin numpy<2.3 in pyproject.toml  
**Verification**: `uv run python -c "import numpy as np; print(np.__version__)"` should show 2.2.x

#### Coverage Module Path Issues  
**Issue**: pytest-cov may report "module never imported"  
**Workaround**: Run tests without coverage first to verify functionality  
**Non-Critical**: Tests passing is more important than coverage reporting

#### Jupyter Notebook Import Errors After Module Changes
**Issue**: Notebook kernel caches imported modules and won't pick up changes to __init__.py  
**Solution**: After making changes to module exports, restart the notebook kernel or run:
```python
import sys
modules_to_delete = [m for m in sys.modules if m.startswith('neural_analysis')]
for m in modules_to_delete:
    del sys.modules[m]
```
**Best Practice**: Always run `uv pip install -e .` after modifying __init__.py files

### Quick Reference Commands

```bash
# Complete quality check sequence
uv run ruff check src/neural_analysis/visualization/plots_1d.py --fix
uv run ruff format src/neural_analysis/visualization/plots_1d.py
uv run pytest tests/test_plots_1d.py -v

# Full CI check
./scripts/run_ci_locally.sh

# Update dependencies after pyproject.toml changes
uv sync && uv pip install -e ".[dev,viz]"

# Check environment versions
uv run python -c "import numpy as np, matplotlib, scipy; print(f'NumPy: {np.__version__}\\nMatplotlib: {matplotlib.__version__}\\nSciPy: {scipy.__version__}')"
```

---

## Module Migration Progress

### ‚úÖ Completed Modules

#### plots_1d Module (2025-01-26)
**Location:** `src/neural_analysis/plotting/plots_1d.py`

**Functions Implemented (3):**
- `plot_line`: Line plots with optional standard deviation bands, markers
- `plot_multiple_lines`: Multiple line plots with automatic color cycling  
- `plot_boolean_states`: Binary state visualization with colored spans

**Metrics:**
- Lines of code: 567
- Tests: 28 passing (test_plots_1d.py)
- Coverage: 100%
- Linting: Clean (ruff)
- Type checking: Clean (mypy, expected stubs warnings only)
- Documentation: Complete

**Notebook:** `examples/plots_1d_examples.ipynb` - 17 cells

---

#### plots_2d Module (2025-01-26)
**Location:** `src/neural_analysis/plotting/plots_2d.py`

**Functions Implemented (4):**
- `plot_scatter_2d`: 2D scatter plots with color mapping and variable marker sizes
- `plot_trajectory_2d`: 2D trajectories with time-based color gradients (matplotlib LineCollection)
- `plot_grouped_scatter_2d`: Multi-group scatter plots with optional convex hulls
- `plot_kde_2d`: 2D kernel density estimation with contour/filled modes

**Metrics:**
- Lines of code: 755
- Tests: 38 passing (test_plots_2d.py) - 7.65s runtime
- Coverage: 100% (all functions, both backends, edge cases)
- Linting: Clean (ruff - 17 errors auto-fixed)
- Type checking: Clean (mypy, expected scipy/plotly stubs warnings only)
- Documentation: Complete

**Notebook:** `examples/plots_2d_examples.ipynb` - 21 cells demonstrating all 4 functions

**Critical Fixes Applied:**
- Plotly trajectory: Changed from `line.color` (doesn't accept arrays) to `marker.color` with colorscale
- Python cache: Cleared `__pycache__` and force-reinstalled package after file edits
- Backend implementations: Separate matplotlib/plotly functions for each plot type

**Dependencies Added:**
- scipy>=1.14 (ConvexHull, gaussian_kde)
- Updated plotly>=5.18 for compatibility

---

### üîÑ Remaining Modules (from Visualizer.py)

#### High Priority
- **plots_3d**: 3D scatter, surface, trajectory visualization
- **embeddings**: 2D/3D embedding visualization with convex hulls
- **heatmaps**: Basic heatmaps, correlation matrices, neural activity heatmaps

#### Medium Priority  
- **statistical**: Histograms with KDE, box plots, violin plots, distribution fitting
- **neural**: Raster plots, calcium traces, spike trains

#### Lower Priority
- **animations**: 2D/3D position animations, neural activity animations

**Note:** Folder was renamed from `visualization/` to `plotting/` to match planned structure.
