{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comprehensive Neural Analysis Example\n",
        "\n",
        "This notebook demonstrates comprehensive neural analysis methods using synthetic datasets. It covers:\n",
        "\n",
        "1. **Test Neural Analysis Methods** - Apply structure_index and shape_distance to various datasets\n",
        "2. **Benchmark Dimensionality Reduction** - Compare PCA, UMAP, t-SNE, MDS, Isomap, LLE, Spectral\n",
        "3. **Validate Decoding Approaches** - Test population vector and k-NN decoders with known ground truth\n",
        "4. **Test Cell Type Classification** - Apply supervised and unsupervised classifiers to mixed populations\n",
        "5. **Study Noise Effects** - Analyze how noise affects embedding quality and analysis methods\n",
        "\n",
        "All visualizations use the **PlotGrid system** for consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Neural analysis imports\n",
        "from neural_analysis.data.synthetic_data import (\n",
        "    generate_place_cells,\n",
        "    generate_grid_cells,\n",
        "    generate_head_direction_cells,\n",
        "    generate_mixed_population_flexible,\n",
        ")\n",
        "from neural_analysis.learning.decoding import (\n",
        "    population_vector_decoder,\n",
        "    knn_decoder,\n",
        "    evaluate_decoder,\n",
        ")\n",
        "from neural_analysis.learning.classification import (\n",
        "    classify_cells,\n",
        "    cluster_cells,\n",
        "    extract_cell_features,\n",
        "    compare_classifiers,\n",
        "    compare_clusterers,\n",
        ")\n",
        "from neural_analysis.embeddings import compute_embedding, compute_multiple_embeddings\n",
        "from neural_analysis.topology import compute_structure_index\n",
        "from neural_analysis.metrics.distributions import shape_distance\n",
        "from neural_analysis.plotting import (\n",
        "    PlotGrid,\n",
        "    PlotSpec,\n",
        "    GridLayoutConfig,\n",
        "    PlotConfig,\n",
        ")\n",
        "\n",
        "# Set random seed\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"✓ Imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Test Neural Analysis Methods with Datasets\n",
        "\n",
        "Generate multiple synthetic datasets and apply structure_index and shape_distance to quantify manifold organization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate different cell types\n",
        "print(\"Generating synthetic datasets...\")\n",
        "\n",
        "# Place cells\n",
        "place_activity, place_meta = generate_place_cells(\n",
        "    n_cells=50, n_samples=1000, arena_size=(2.0, 2.0), seed=42, plot=False\n",
        ")\n",
        "\n",
        "# Grid cells\n",
        "grid_activity, grid_meta = generate_grid_cells(\n",
        "    n_cells=50, n_samples=1000, arena_size=(2.0, 2.0), seed=43, plot=False\n",
        ")\n",
        "\n",
        "# Head direction cells\n",
        "hd_activity, hd_meta = generate_head_direction_cells(\n",
        "    n_cells=50, n_samples=1000, seed=44, plot=False\n",
        ")\n",
        "\n",
        "# Mixed population\n",
        "mixed_activity, mixed_meta = generate_mixed_population_flexible(\n",
        "    n_samples=1000, seed=45, plot=False\n",
        ")\n",
        "\n",
        "print(f\"Place cells: {place_activity.shape}\")\n",
        "print(f\"Grid cells: {grid_activity.shape}\")\n",
        "print(f\"Head direction cells: {hd_activity.shape}\")\n",
        "print(f\"Mixed population: {mixed_activity.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute structure index for each dataset\n",
        "print(\"\\nComputing Structure Index...\")\n",
        "\n",
        "datasets = {\n",
        "    'place': (place_activity, place_meta['positions']),\n",
        "    'grid': (grid_activity, grid_meta['positions']),\n",
        "    'head_direction': (hd_activity, hd_meta['head_directions'].reshape(-1, 1)),\n",
        "    'mixed': (mixed_activity, mixed_meta['positions']),\n",
        "}\n",
        "\n",
        "si_results = {}\n",
        "for name, (activity, labels) in datasets.items():\n",
        "    try:\n",
        "        si, _, _, _ = compute_structure_index(\n",
        "            activity, labels, n_bins=10, n_neighbors=15, num_shuffles=10\n",
        "        )\n",
        "        si_results[name] = si\n",
        "        print(f\"  {name}: SI = {si:.3f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  {name}: Error - {e}\")\n",
        "        si_results[name] = np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute shape similarity between datasets\n",
        "print(\"\\nComputing shape similarity...\")\n",
        "\n",
        "# Compare place vs grid\n",
        "place_sample = place_activity[:500]\n",
        "grid_sample = grid_activity[:500]\n",
        "\n",
        "shape_dist, _ = shape_distance(\n",
        "    place_sample, grid_sample, method='procrustes'\n",
        ")\n",
        "print(f\"Place vs Grid (Procrustes): {shape_dist:.3f}\")\n",
        "\n",
        "# Compare place vs mixed\n",
        "mixed_sample = mixed_activity[:500]\n",
        "shape_dist2, _ = shape_distance(\n",
        "    place_sample, mixed_sample, method='procrustes'\n",
        ")\n",
        "print(f\"Place vs Mixed (Procrustes): {shape_dist2:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Benchmark Dimensionality Reduction Algorithms\n",
        "\n",
        "Compare multiple DR methods on synthetic datasets with known structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use place cells for DR benchmarking\n",
        "data = place_activity\n",
        "labels = place_meta['positions']\n",
        "\n",
        "# Compute multiple embeddings\n",
        "print(\"Computing embeddings...\")\n",
        "methods = ['pca', 'umap', 'tsne', 'mds', 'isomap', 'lle', 'spectral']\n",
        "embeddings = {}\n",
        "times = {}\n",
        "\n",
        "for method in methods:\n",
        "    try:\n",
        "        start = time.time()\n",
        "        emb = compute_embedding(\n",
        "            data, method=method, n_components=2, random_state=42\n",
        "        )\n",
        "        elapsed = time.time() - start\n",
        "        embeddings[method] = emb\n",
        "        times[method] = elapsed\n",
        "        print(f\"  {method}: {elapsed:.3f}s\")\n",
        "    except Exception as e:\n",
        "        print(f\"  {method}: Error - {e}\")\n",
        "        embeddings[method] = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate embeddings with structure index\n",
        "print(\"\\nEvaluating embeddings with structure index...\")\n",
        "embedding_si = {}\n",
        "\n",
        "for method, emb in embeddings.items():\n",
        "    if emb is not None:\n",
        "        try:\n",
        "            si, _, _, _ = compute_structure_index(\n",
        "                emb, labels, n_bins=10, n_neighbors=15, num_shuffles=5\n",
        "            )\n",
        "            embedding_si[method] = si\n",
        "            print(f\"  {method}: SI = {si:.3f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  {method}: SI computation failed - {e}\")\n",
        "            embedding_si[method] = np.nan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize embeddings using PlotGrid\n",
        "plot_specs = []\n",
        "methods_to_plot = ['pca', 'umap', 'tsne', 'isomap']\n",
        "\n",
        "for idx, method in enumerate(methods_to_plot):\n",
        "    if embeddings.get(method) is not None:\n",
        "        emb = embeddings[method]\n",
        "        spec = PlotSpec(\n",
        "            data={'x': emb[:, 0], 'y': emb[:, 1]},\n",
        "            plot_type='scatter',\n",
        "            subplot_position=idx,\n",
        "            title=f'{method.upper()} Embedding',\n",
        "            color_by=labels[:, 0],  # Color by X position\n",
        "            cmap='viridis',\n",
        "            marker_size=10,\n",
        "            alpha=0.6,\n",
        "            kwargs={'x_label': 'Dim 1', 'y_label': 'Dim 2'}\n",
        "        )\n",
        "        plot_specs.append(spec)\n",
        "\n",
        "if plot_specs:\n",
        "    grid = PlotGrid(\n",
        "        plot_specs=plot_specs,\n",
        "        config=PlotConfig(figsize=(16, 4)),\n",
        "        layout=GridLayoutConfig(rows=1, cols=len(plot_specs)),\n",
        "        backend='matplotlib'\n",
        "    )\n",
        "    fig = grid.plot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 3: Validate Decoding Approaches with Known Ground Truth\n",
        "\n",
        "Test decoding methods on place cells, grid cells, and head direction cells with known positions/angles.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test population vector decoder on place cells\n",
        "print(\"Testing Population Vector Decoder...\")\n",
        "decoded_pos = population_vector_decoder(\n",
        "    place_activity, place_meta['field_centers'], method='weighted_average'\n",
        ")\n",
        "\n",
        "# Compute decoding error\n",
        "errors = np.linalg.norm(decoded_pos - place_meta['positions'], axis=1)\n",
        "print(f\"  Mean error: {errors.mean():.3f} m\")\n",
        "print(f\"  Median error: {np.median(errors):.3f} m\")\n",
        "\n",
        "# Test k-NN decoder\n",
        "print(\"\\nTesting k-NN Decoder...\")\n",
        "n_train = 700\n",
        "train_act = place_activity[:n_train]\n",
        "train_pos = place_meta['positions'][:n_train]\n",
        "test_act = place_activity[n_train:]\n",
        "test_pos = place_meta['positions'][n_train:]\n",
        "\n",
        "decoded_knn = knn_decoder(train_act, train_pos, test_act, k=5)\n",
        "errors_knn = np.linalg.norm(decoded_knn - test_pos, axis=1)\n",
        "print(f\"  Mean error: {errors_knn.mean():.3f} m\")\n",
        "print(f\"  Median error: {np.median(errors_knn):.3f} m\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare high-D vs low-D decoding\n",
        "print(\"\\nComparing High-D vs Low-D Decoding...\")\n",
        "\n",
        "# High-D (raw activity)\n",
        "metrics_highd = evaluate_decoder(\n",
        "    train_act, train_pos, test_act, test_pos, decoder='knn', k=5\n",
        ")\n",
        "\n",
        "# Low-D (PCA embedding)\n",
        "pca_emb = compute_embedding(place_activity, method='pca', n_components=10, random_state=42)\n",
        "train_emb = pca_emb[:n_train]\n",
        "test_emb = pca_emb[n_train:]\n",
        "\n",
        "metrics_lowd = evaluate_decoder(\n",
        "    train_emb, train_pos, test_emb, test_pos, decoder='knn', k=5\n",
        ")\n",
        "\n",
        "print(f\"High-D R²: {metrics_highd['r2_score']:.3f}, Error: {metrics_highd['mean_error']:.3f}\")\n",
        "print(f\"Low-D R²: {metrics_lowd['r2_score']:.3f}, Error: {metrics_lowd['mean_error']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 4: Test Cell Type Classification on Mixed Populations\n",
        "\n",
        "Apply supervised and unsupervised classifiers to identify cell types in mixed populations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract features from mixed population\n",
        "print(\"Extracting features from mixed population...\")\n",
        "mixed_features = extract_cell_features(mixed_activity, mixed_meta)\n",
        "mixed_cell_types = mixed_meta['cell_types']\n",
        "\n",
        "print(f\"Features shape: {mixed_features.shape}\")\n",
        "print(f\"Cell types: {np.unique(mixed_cell_types, return_counts=True)}\")\n",
        "\n",
        "# Split train/test\n",
        "n_train = len(mixed_features) // 2\n",
        "train_feat = mixed_features[:n_train]\n",
        "train_labels = mixed_cell_types[:n_train]\n",
        "test_feat = mixed_features[n_train:]\n",
        "test_labels = mixed_cell_types[n_train:]\n",
        "\n",
        "# Compare classifiers\n",
        "print(\"\\nComparing supervised classifiers...\")\n",
        "classifier_results = compare_classifiers(\n",
        "    train_feat, train_labels, test_feat, test_labels,\n",
        "    methods=['random_forest', 'svc', 'knn', 'logistic_regression'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Display results\n",
        "for method, metrics in classifier_results.items():\n",
        "    if 'error' not in metrics:\n",
        "        print(f\"  {method}: Accuracy = {metrics['accuracy']:.3f}, F1 = {metrics['f1']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test unsupervised clustering\n",
        "print(\"\\nComparing unsupervised clusterers...\")\n",
        "n_clusters = len(np.unique(mixed_cell_types))\n",
        "\n",
        "clustering_results = compare_clusterers(\n",
        "    mixed_features,\n",
        "    n_clusters=n_clusters,\n",
        "    true_labels=mixed_cell_types,\n",
        "    methods=['kmeans', 'gaussian_mixture', 'agglomerative'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Display results\n",
        "for method, metrics in clustering_results.items():\n",
        "    if 'error' not in metrics:\n",
        "        print(f\"  {method}: ARI = {metrics.get('adjusted_rand_score', np.nan):.3f}, \"\n",
        "              f\"Silhouette = {metrics['silhouette_score']:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 5: Study How Noise Affects Embedding Quality\n",
        "\n",
        "Generate datasets with varying noise levels and analyze how noise affects embedding quality, structure index, and decoding performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate datasets with varying noise levels\n",
        "print(\"Generating datasets with varying noise...\")\n",
        "noise_levels = np.linspace(0.0, 1.0, 6)\n",
        "noise_results = []\n",
        "\n",
        "for noise in noise_levels:\n",
        "    print(f\"\\nNoise level: {noise:.2f}\")\n",
        "    \n",
        "    # Generate place cells with noise\n",
        "    activity, meta = generate_place_cells(\n",
        "        n_cells=50, n_samples=1000, arena_size=(2.0, 2.0),\n",
        "        noise_level=noise, seed=42, plot=False\n",
        "    )\n",
        "    positions = meta['positions']\n",
        "    \n",
        "    # Compute structure index\n",
        "    try:\n",
        "        si, _, _, _ = compute_structure_index(\n",
        "            activity, positions, n_bins=10, n_neighbors=15, num_shuffles=5\n",
        "        )\n",
        "    except:\n",
        "        si = np.nan\n",
        "    \n",
        "    # Compute embeddings\n",
        "    embeddings_noise = {}\n",
        "    for method in ['pca', 'umap']:\n",
        "        try:\n",
        "            emb = compute_embedding(\n",
        "                activity, method=method, n_components=2, random_state=42\n",
        "            )\n",
        "            embeddings_noise[method] = emb\n",
        "        except:\n",
        "            embeddings_noise[method] = None\n",
        "    \n",
        "    # Compute shape similarity to clean embedding (noise=0)\n",
        "    if noise > 0 and embeddings_noise.get('pca') is not None:\n",
        "        # Get clean embedding\n",
        "        clean_activity, _ = generate_place_cells(\n",
        "            n_cells=50, n_samples=1000, arena_size=(2.0, 2.0),\n",
        "            noise_level=0.0, seed=42, plot=False\n",
        "        )\n",
        "        clean_emb = compute_embedding(\n",
        "            clean_activity, method='pca', n_components=2, random_state=42\n",
        "        )\n",
        "        shape_dist, _ = shape_distance(\n",
        "            clean_emb[:500], embeddings_noise['pca'][:500], method='procrustes'\n",
        "        )\n",
        "    else:\n",
        "        shape_dist = 0.0\n",
        "    \n",
        "    # Test decoding\n",
        "    n_train = 700\n",
        "    train_act = activity[:n_train]\n",
        "    train_pos = positions[:n_train]\n",
        "    test_act = activity[n_train:]\n",
        "    test_pos = positions[n_train:]\n",
        "    \n",
        "    metrics = evaluate_decoder(\n",
        "        train_act, train_pos, test_act, test_pos, decoder='knn', k=5\n",
        "    )\n",
        "    \n",
        "    noise_results.append({\n",
        "        'noise': noise,\n",
        "        'si': si,\n",
        "        'shape_dist': shape_dist,\n",
        "        'decoding_error': metrics['mean_error'],\n",
        "        'decoding_r2': metrics['r2_score'],\n",
        "    })\n",
        "    \n",
        "    print(f\"  SI: {si:.3f}, Shape dist: {shape_dist:.3f}, \"\n",
        "          f\"Decoding error: {metrics['mean_error']:.3f}\")\n",
        "\n",
        "noise_df = pd.DataFrame(noise_results)\n",
        "print(\"\\nNoise Analysis Results:\")\n",
        "print(noise_df.round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize noise effects using PlotGrid\n",
        "plot_specs = []\n",
        "\n",
        "# Structure Index vs Noise\n",
        "spec1 = PlotSpec(\n",
        "    data={'x': noise_df['noise'], 'y': noise_df['si']},\n",
        "    plot_type='line',\n",
        "    subplot_position=0,\n",
        "    title='Structure Index vs Noise',\n",
        "    color='steelblue',\n",
        "    marker='o',\n",
        "    line_width=2,\n",
        "    kwargs={'x_label': 'Noise Level', 'y_label': 'Structure Index'}\n",
        ")\n",
        "plot_specs.append(spec1)\n",
        "\n",
        "# Decoding Error vs Noise\n",
        "spec2 = PlotSpec(\n",
        "    data={'x': noise_df['noise'], 'y': noise_df['decoding_error']},\n",
        "    plot_type='line',\n",
        "    subplot_position=1,\n",
        "    title='Decoding Error vs Noise',\n",
        "    color='coral',\n",
        "    marker='o',\n",
        "    line_width=2,\n",
        "    kwargs={'x_label': 'Noise Level', 'y_label': 'Mean Error (m)'}\n",
        ")\n",
        "plot_specs.append(spec2)\n",
        "\n",
        "# Shape Distance vs Noise\n",
        "spec3 = PlotSpec(\n",
        "    data={'x': noise_df['noise'], 'y': noise_df['shape_dist']},\n",
        "    plot_type='line',\n",
        "    subplot_position=2,\n",
        "    title='Shape Distance vs Noise',\n",
        "    color='green',\n",
        "    marker='o',\n",
        "    line_width=2,\n",
        "    kwargs={'x_label': 'Noise Level', 'y_label': 'Shape Distance'}\n",
        ")\n",
        "plot_specs.append(spec3)\n",
        "\n",
        "grid = PlotGrid(\n",
        "    plot_specs=plot_specs,\n",
        "    config=PlotConfig(figsize=(15, 5)),\n",
        "    layout=GridLayoutConfig(rows=1, cols=3),\n",
        "    backend='matplotlib'\n",
        ")\n",
        "fig = grid.plot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This comprehensive example demonstrated:\n",
        "\n",
        "1. **Structure Index Analysis** - Quantified manifold organization across different cell types\n",
        "2. **Dimensionality Reduction Benchmarking** - Compared 7 DR methods on synthetic data\n",
        "3. **Decoding Validation** - Tested population vector and k-NN decoders with ground truth\n",
        "4. **Cell Type Classification** - Applied supervised and unsupervised methods to mixed populations\n",
        "5. **Noise Impact Study** - Analyzed how noise affects embedding quality and decoding performance\n",
        "\n",
        "All methods are integrated and ready for use with your neural data!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
